---
layout: archive
# title: "Research"
permalink: /research/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Publications
======
* Saurabh Kumar, Henrik Marklund, Ashish Rao, Yifan Zhu, Hong Jun Jeon, **Yueyang Liu**, Benjamin Van Roy, [Continual Learning as Computationally Constrained Reinforcement Learning](https://arxiv.org/abs/2307.04345), 2023.
  * "An agent shall aim to maximize long-term average reward subject to computational constraints."
* **Yueyang Liu**, Xu Kuang, and Benjamin Van Roy, [A Definition of Non-Stationary Bandits](https://arxiv.org/abs/2302.12202), 2023.
  * "Definitions, notions of regret, and agents should depend only on the observables but not on latent models."
  * Presented at Stanford Data Science Conference 2023, SIAM Conference on Optimization 2023, Experimentation and Causal Inference in the Tech Sector Workshop 2023.
  * To be submitted to *Management Science*. 
* **Yueyang Liu**, Xu Kuang, and Benjamin Van Roy, [Non-Stationary Bandit Learning via Predictive Sampling](https://arxiv.org/abs/2205.01970), 2022.
  * "An agent should prioritize seeking lasting information."
  * Presented at 2022 INFORMS Annual Meeting, Stanford University MS&E Rising Stars Workshop 2023, AISTATS 2023. 
  * A preliminary version appears in International Conference on Artificial Intelligence and Statistics (AISTATS) 2023.
  * Under review at *Management Science*. 
* **Yueyang Liu**, Adithya M. Devraj, Benjamin Van Roy, and Kuang Xu, [Gaussian Imagination in Bandit Learning](https://arxiv.org/abs/2201.01902), 2022.
  * "Bayesian agents remain effective when instantiated with sufficiently diffuse Gaussian prior and likelihood distributions." 
  
